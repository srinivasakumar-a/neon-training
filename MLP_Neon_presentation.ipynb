{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron for MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A perceptron is a single neuron model that is a precursor to larger neural networks. It is a simple binary classifer (linear) to separate data between two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_binary.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_binary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The goal is to develop robust algorithms and data structures that we can use to model difficult problems.\n",
    "\n",
    "The power of neural networks come from their ability to **learn the representation** in your training data and how to best relate it to the output variable that you want to predict. In this sense neural networks learn a mapping.\n",
    "\n",
    "The predictive capability of neural networks comes from the multi-layered structure of the networks. The data structure can pick out (learn to represent) features at different scales or resolutions and combine them into higher-order features. For example from lines, to collections of lines to shapes.\n",
    "\n",
    "For more information on MLP visit https://machinelearningmastery.com/neural-networks-crash-course/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hidden layers are called \"hidden\" because their values are not given in the input data. Instead, the previous layer of the model provides a new representation of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.safaribooksonline.com/library/view/getting-started-with/9781786468574/graphics/B05474_04_05.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.safaribooksonline.com/library/view/getting-started-with/9781786468574/graphics/B05474_04_05.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example of different representations between hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://playground.tensorflow.org/preview.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://playground.tensorflow.org/preview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MINST is a database consisting of handwritten digits between 0-9. Each image is a 28 x 28 pixel grayscale for a total of 784 features.\n",
    "\n",
    "A multi-layer perceptron model is trained and tested on 70,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://guillaumebrg.files.wordpress.com/2016/01/mnist_and_mlp1.png?w=507&h=222\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://guillaumebrg.files.wordpress.com/2016/01/mnist_and_mlp1.png?w=507&h=222\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate a Backend "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neon features highly optimized CPU (MKL) and GPU computational backends for fast matrix operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neon.backends.nervanacpu.NervanaCPU at 0x10ca5ea20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neon.backends import gen_backend\n",
    "\n",
    "# batch_size = (num of training examples per epoch)\n",
    "gen_backend(backend='cpu', batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The neon backend is easily swappable, meaning that the same code will run for both the GPU and CPU backends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MNIST Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The MNIST dataset can be found on Yann LeCunn’s website. Neon provides an easy function that downloads the MNIST dataset into your nervana/data/ directory and loads it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.data import MNIST\n",
    "\n",
    "mnist = MNIST()\n",
    "\n",
    "(X_train, y_train), (X_test, y_test), nclass = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This function automatically splits the images X and labels y into training (60,000 examples) and testing (10,000 examples) data. The training images X_train is a numpy array with shape (num_examples, num_features) = (60000, 784)\n",
    "\n",
    "Nclass is set to 10 to represent the 10 classes that need to be classified (digits: 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To view a sample image in the training dataset, reshape the numpy array (28, 28) and load the image using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118f26860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwRF+IGg/g9u3HZr7xcc8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11897fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfmBpCg/kBTlB5Ki/EBSlB9I6v8BZOIGXzoUqLUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c724588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3): # Show first three images in train data\n",
    "    sample_image = X_train[i].reshape(28,28)\n",
    "\n",
    "    plt.imshow(sample_image)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "During training, neon iterates over the training examples to compute the gradients. We use the following commands to set up the ArrayIterator object that we send to the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.data import ArrayIterator\n",
    "\n",
    "#  (num_examples, num_features) = (60000, 784).\n",
    "train_set = ArrayIterator(X_train, y_train, nclass=nclass)\n",
    "#  (num_examples, num_features) = (10000, 784).\n",
    "test_set = ArrayIterator(X_test, y_test, nclass=nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since MNIST is a small dataset, the set up for the ArrayIterator object is relatively easy. However, for large datasets that cannot fit into memory (e.g. ImageNet or Sports-1M), the data has to be efficiently loaded and fed to the optimizer in batches. This requires more advanced iterators described in Loading Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hyperparameters required to the deep learning model:\n",
    "- a list of layers\n",
    "- a cost function\n",
    "- a learning rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model architecture: Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Initializing weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neon contains an array of intializers. For the MLP MNIST tutorial we intialize the weights using a Gaussian distribution with zero mean and 0.01 standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.initializers import Gaussian\n",
    "\n",
    "def initialize_weights():\n",
    "    \"\"\"\n",
    "    This is a function to Initialize the weights using a Normal Gaussian Distribution \n",
    "    \"\"\"\n",
    "    init_norm = Gaussian(loc=0.0, scale=0.01)\n",
    "    return init_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Affine layer object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neon creates linear layers using Affine function. The parameters required are:\n",
    "- nout: desired size or shape of layer output\n",
    "- init: initializer object to use for initializing layer weights\n",
    "- activation: defines the output of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.layers import Affine\n",
    "\n",
    "def createAffine(n_hidden,activation_func,weight_init):\n",
    "    \"\"\"\n",
    "    This method creates a AFFINE (Fully Connected Hidden Layer). \n",
    "    This is a normal linear layer used in Neural Networks.\n",
    "    \n",
    "    Params:\n",
    "    @ n_hidden        : No of hidden units to use in the layer\n",
    "    @ weight_init     : The weight Initializer to be used to initialize weights in this layer\n",
    "    @ activation_func : The activation function to be used in the layer\n",
    "    \n",
    "    Returns:\n",
    "    Affine Layer Object\n",
    "    \"\"\"\n",
    "    return Affine(nout=n_hidden, init=weight_init, activation=activation_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.transforms import Rectlin, Softmax\n",
    "\n",
    "def create_hidden_layers(layers,\n",
    "                         no_of_layers,\n",
    "                         hidden_unit_list,\n",
    "                         activ_func_list,\n",
    "                         weight_init_list):\n",
    "    \"\"\"\n",
    "    This method creates the complete hidden layer architecture.\n",
    "    \n",
    "    Params:\n",
    "    @ layers           : This is a list containing any previous layers or no layers \n",
    "    @ no_of_layers     : The no of hidden layers to create\n",
    "    @ hidden_unit_list : A list of no of hidden units to use in each layer\n",
    "    @ activ_func_list  : A list of Activation functions to be used in each layer\n",
    "    @ weight_init_list : A list of weight initializers to be used in each layer\n",
    "    \n",
    "    Returns:\n",
    "    A list of the newly created hidden layers\n",
    "    \"\"\"\n",
    "    for index,num in enumerate(hidden_unit_list):\n",
    "        layers.append(createAffine(n_hidden=num,\n",
    "                                   weight_init=weight_init_list[index],\n",
    "                                   activation_func=activ_func_list[index]))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The model is specified as a list of layers. For classifying MNIST images, we use a multi-layer perceptron with fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "no_of_layers = 3\n",
    "hidden_unit_list = [30,50,10]\n",
    "activ_func_list = [Rectlin(),Rectlin(),Softmax()]\n",
    "weight_init_list = [initialize_weights() for i in range(len(hidden_unit_list))]\n",
    "layers = create_hidden_layers(layers,\n",
    "                              no_of_layers,\n",
    "                              hidden_unit_list,\n",
    "                              activ_func_list,\n",
    "                              weight_init_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Three Affine layers are created:\n",
    "- 1st hidden layer with 30 hidden units and a rectified linear activation function, Rectlin()\n",
    "- 2nd hidden layer with 50 hidden units and a rectified linear activation function, Rectlin()\n",
    "- Output layer with 10 units to match the number of labels (classes) in the MNIST dataset. Activation function Softmax() is used to ensure the outputs sum to one and are within the range [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Initalize model object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.models import Model\n",
    "\n",
    "mlp = Model(layers=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The cost function is wrapped within a GeneralizedCost layer, which handles the comparison of the outputs with the provided labels in the dataset. One common cost function which we use here is the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.layers import GeneralizedCost\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Benefits of cost function:\n",
    "- make our networks better at generalizing beyond the training data\n",
    "- better method for intializing the weights in the network\n",
    "- set of heuristics to help choose good hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For learning, we use stochastic gradient descent with a learning rate of 0.1 and momentum coefficient of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.optimizers import GradientDescentMomentum\n",
    "\n",
    "optimizer = GradientDescentMomentum(0.1, momentum_coef=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Callbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neon provides an API for calling operations during the model fit. Here we set up the default callback, which is displaying a progress bar for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.callbacks.callbacks import ProgressBarCallback\n",
    "\n",
    "callbacks = Callbacks(mlp, eval_set=test_set)\n",
    "callbacks.add_callback(ProgressBarCallback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At the beginning of the fitting procedure, neon propagates train_set through the model to set the input and output shapes of each layer. Each layer has a configure() method that determines the appropriate layer shapes, and an allocate() method to set up the needed buffers for holding the forward propagation information.\n",
    "\n",
    "During the training, neon sends batches of the training data through the model, calling each layers’ fprop() and bprop() methods to compute the gradients and update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   [Train |████████████████████|  469/469  batches, 0.24 cost, 3.39s]\n",
      "\n",
      "Epoch 1   [Train |████████████████████|  469/469  batches, 0.15 cost, 3.71s]\n",
      "\n",
      "Epoch 2   [Train |████████████████████|  469/469  batches, 0.12 cost, 3.91s]\n",
      "\n",
      "Epoch 3   [Train |████████████████████|  468/468  batches, 0.11 cost, 3.83s]\n",
      "\n",
      "Epoch 4   [Train |████████████████████|  468/468  batches, 0.12 cost, 3.94s]\n",
      "\n",
      "Epoch 5   [Train |████████████████████|  468/468  batches, 0.11 cost, 3.97s]\n",
      "\n",
      "Epoch 6   [Train |████████████████████|  468/468  batches, 0.12 cost, 3.98s]\n",
      "\n",
      "Epoch 7   [Train |████████████████████|  468/468  batches, 0.09 cost, 4.16s]\n",
      "\n",
      "Epoch 8   [Train |████████████████████|  468/468  batches, 0.09 cost, 3.94s]\n",
      "\n",
      "Epoch 9   [Train |████████████████████|  468/468  batches, 0.09 cost, 3.90s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(dataset=train_set,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=10, # epoch = (num of passes of all the training examples)\n",
    "        cost=cost,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the trained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The model is now trained, we can used the trained model to classify an image, measure performance, and visualize the weights and training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given the images from the test_set, fetch the output of the final model layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# (num_test_examples, num_outputs) = (10000,10)\n",
    "results = mlp.get_outputs(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neon supports functions for evaluating performance using custom metrics. Here we measure the misclassification rate on the held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification error = 5.5%\n"
     ]
    }
   ],
   "source": [
    "from neon.transforms import Misclassification\n",
    "\n",
    "# evaluate the model on test_set using the misclassification metric\n",
    "error = mlp.eval(test_set, metric=Misclassification())*100\n",
    "print('Misclassification error = %.1f%%' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### View misclassified images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model misclassified image as: 7\n",
      "Correct image label is: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwjq/wHNw1a+oGwPlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1187253c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "misclassified_img = []\n",
    "for row in range(results.shape[0]):\n",
    "    a = results[row]\n",
    "    i = np.unravel_index(a.argmax(), a.shape)\n",
    "\n",
    "    if (i[0] == y_test[row]) == False:\n",
    "        misclassified_img.append(row)\n",
    "\n",
    "a = results[misclassified_img[0]]\n",
    "i = np.unravel_index(a.argmax(), a.shape)\n",
    "\n",
    "print('Model misclassified image as:', i[0])\n",
    "print('Correct image label is:', y_test[misclassified_img[0]])\n",
    "\n",
    "plt.imshow(X_test[misclassified_img[0]].reshape(28,28))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
